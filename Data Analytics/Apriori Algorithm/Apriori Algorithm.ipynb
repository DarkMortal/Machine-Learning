{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51d5f459-7f31-4f01-bae3-1a3f9cc14f23",
   "metadata": {},
   "source": [
    "# Market basket analysis\n",
    "<br/>\n",
    "Apriori is a classic frequent-itemset mining algorithm that finds groups of items (itemsets) that appear together frequently in a transaction database, and then derives association rules from them.\n",
    "\n",
    "### Core idea\n",
    "Use the **Apriori property** — *if an itemset is frequent, then all its subsets are frequent* — to generate candidates level-by-level (size-1, size-2, …) and prune any candidate whose subset is known to be infrequent.\n",
    "## Common use cases\n",
    "- Market-basket analysis (what products are bought together) — cross-sell, store layout.\n",
    "- Recommendation systems and product bundling.\n",
    "- Web / clickstream pattern mining (pages visited together).\n",
    "- Bioinformatics (frequent co-occurring genetic markers).\n",
    "- Fraud or intrusion detection (frequent suspicious combinations).\n",
    "\n",
    "## High-level step-by-step algorithm\n",
    "1. **Input:** transaction database, `min_support` (threshold), optionally `min_confidence`.\n",
    "2. **Scan 1:** generate all 1-item candidates ($C_1$), count supports, keep frequent ones $\\rightarrow L_1$.\n",
    "3. **For $k = 2, 3, ...$ until $L_{k-1}$ is empty:**\n",
    "   - **Join:** form candidate $k$-itemsets $C_k$ by joining pairs of frequent $(k−1)$-itemsets from $L_{k-1}$.\n",
    "   - **Prune:** remove any candidate in $C_k$ that has at least one $(k−1)$ subset not in $L_{k-1}$ (Apriori property).\n",
    "   - **Count:** scan dataset to compute support for each candidate in $C_k$.\n",
    "   - **Select:** let $L_k = \\{c\\in C_k | $support$(c) ≥ $min_support$\\}$.\n",
    "4. **Collect:** all $L_k$ form the set of frequent itemsets.\n",
    "5. **Rule generation:** for each frequent itemset $F$ of size $\\geq 2$, enumerate non-empty proper subsets $A$, form rule $A\\rightarrow (F/A)$.\n",
    "    <br/>Compute `confidence = support(F) / support(A)` and keep the rules with `confidence ≥ min_confidence`.\n",
    "    <br/>Confidence is nothing but the conditional probability of $F$ w.r.t $A$, i.e, probability of $F$ occuring given that $A$ has already occured.\n",
    "6. **Output:** frequent itemsets and association rules (optionally filtered by confidence).\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "875999fd-0df7-4fb3-98db-67c84653420e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    \"\"\"Sample data for testing\"\"\"\n",
    "    return [\n",
    "        ['milk', 'bread', 'nuts', 'apple'],\n",
    "        ['milk', 'bread', 'nuts'],\n",
    "        ['milk', 'bread'],\n",
    "        ['milk', 'bread', 'apple'],\n",
    "        ['milk', 'bread', 'apple']\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1c8dbd-a6f1-4d06-b5ef-c4a4f5d98c29",
   "metadata": {},
   "source": [
    "## Generate candidate itemsets of size $k$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5d5923d-7649-415b-96bb-44c292e84301",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def create_candidates_from_dataset(dataset, k):\n",
    "    candidates = set()\n",
    "    for transaction in dataset:\n",
    "        for combo in combinations(sorted(transaction), k):\n",
    "            candidates.add(combo)\n",
    "    return list(candidates)\n",
    "\n",
    "def create_candidates_from_unique_items(items, k):\n",
    "    \"\"\"\n",
    "    Generate candidate itemsets of size k from a list of unique items.\n",
    "    \n",
    "    Args:\n",
    "        items (list/iterable): unique items (e.g., ['milk', 'bread', 'apple'])\n",
    "        k (int): size of each candidate itemset\n",
    "    \n",
    "    Returns:\n",
    "        list of tuples: candidate itemsets\n",
    "    \"\"\"\n",
    "    return [tuple(sorted(c)) for c in combinations(items, k)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5a3612-1bc4-4443-af18-564ffc7b3d18",
   "metadata": {},
   "source": [
    "## Calculate support for each candidate and filter based on `min_support`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ead0d8f-4381-4cab-8786-c57871ff1bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_support(dataset, candidates, min_support = 0.5):\n",
    "    item_count = {}\n",
    "    total_transactions = len(dataset)\n",
    "\n",
    "    for transaction in dataset:\n",
    "        transaction_set = set(transaction)\n",
    "        for candidate in candidates:\n",
    "            if set(candidate).issubset(transaction_set):\n",
    "                item_count[candidate] = item_count.get(candidate, 0) + 1\n",
    "\n",
    "    # Filter with min_support\n",
    "    frequent_items = []\n",
    "    support_data = {}\n",
    "    for item, count in item_count.items():\n",
    "        support = count / total_transactions\n",
    "        if support >= min_support:\n",
    "            frequent_items.append(item)\n",
    "        support_data[item] = support\n",
    "\n",
    "    return frequent_items, support_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efaf2847-cf60-4b5e-b689-2623733b6fce",
   "metadata": {},
   "source": [
    "## Function to generate antededents and consequents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7eea1226-1ee8-4184-935f-45bf241d5229",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def generate_antecedent_consequent(itemset):\n",
    "    \"\"\"\n",
    "    Given an itemset, generate all possible (antecedent, consequent) pairs.\n",
    "    Each antecedent is a non-empty proper subset of the itemset.\n",
    "    Consequent = itemset - antecedent\n",
    "    \"\"\"\n",
    "    itemset = set(itemset)\n",
    "    pairs = []\n",
    "    \n",
    "    # Generate all non-empty proper subsets\n",
    "    for i in range(1, len(itemset)):\n",
    "        for antecedent in combinations(itemset, i):\n",
    "            antecedent = set(antecedent)\n",
    "            consequent = itemset - antecedent\n",
    "            pairs.append((antecedent, consequent))\n",
    "    \n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4854545-af43-4c31-9359-db186a5ac351",
   "metadata": {},
   "source": [
    "## Generate unique items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "783da7d8-d74b-4d56-beb5-0ae71f298c08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apple', 'nuts', 'milk', 'bread']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset()\n",
    "unique_items = create_candidates_from_dataset(dataset, 1)\n",
    "unique_items = list(map(lambda x: x[0], unique_items))\n",
    "unique_items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0ce97c-8662-4b82-b269-72418d8cb3de",
   "metadata": {},
   "source": [
    "## Generating item-sets example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8a9827c-e043-46c0-ad22-add6942d8bce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('apple', 'nuts'),\n",
       " ('apple', 'milk'),\n",
       " ('apple', 'bread'),\n",
       " ('milk', 'nuts'),\n",
       " ('bread', 'nuts'),\n",
       " ('bread', 'milk')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TODO: generate item-sets of 2\n",
    "create_candidates_from_unique_items(unique_items, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b70218a-4079-40b8-ba58-cd691d2b85f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('apple', 'milk', 'nuts'),\n",
       " ('apple', 'bread', 'nuts'),\n",
       " ('apple', 'bread', 'milk'),\n",
       " ('bread', 'milk', 'nuts')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TODO: generate item-sets of 3\n",
    "create_candidates_from_unique_items(unique_items, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454936b2-b798-454d-b4d5-5e760691a9be",
   "metadata": {},
   "source": [
    "## Generate antecedents and consequents example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9029780e-92d6-4105-9ad0-be99b3a861ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items: ['apple', 'nuts', 'milk', 'bread']\n",
      "\n",
      "Antecedent: {'milk'}, Consequent: {'apple', 'nuts', 'bread'}\n",
      "Antecedent: {'apple'}, Consequent: {'milk', 'nuts', 'bread'}\n",
      "Antecedent: {'nuts'}, Consequent: {'milk', 'apple', 'bread'}\n",
      "Antecedent: {'bread'}, Consequent: {'milk', 'apple', 'nuts'}\n",
      "Antecedent: {'milk', 'apple'}, Consequent: {'nuts', 'bread'}\n",
      "Antecedent: {'milk', 'nuts'}, Consequent: {'apple', 'bread'}\n",
      "Antecedent: {'milk', 'bread'}, Consequent: {'apple', 'nuts'}\n",
      "Antecedent: {'apple', 'nuts'}, Consequent: {'milk', 'bread'}\n",
      "Antecedent: {'apple', 'bread'}, Consequent: {'milk', 'nuts'}\n",
      "Antecedent: {'nuts', 'bread'}, Consequent: {'milk', 'apple'}\n",
      "Antecedent: {'milk', 'apple', 'nuts'}, Consequent: {'bread'}\n",
      "Antecedent: {'milk', 'apple', 'bread'}, Consequent: {'nuts'}\n",
      "Antecedent: {'milk', 'nuts', 'bread'}, Consequent: {'apple'}\n",
      "Antecedent: {'apple', 'nuts', 'bread'}, Consequent: {'milk'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Items: {unique_items}\\n\")\n",
    "pairs = generate_antecedent_consequent(unique_items)\n",
    "\n",
    "for antecedent, consequent in pairs:\n",
    "    print(f\"Antecedent: {antecedent}, Consequent: {consequent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24ce386c-6df7-4faa-8dd1-ffd82a186881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: {'Candidates': [('apple',), ('nuts',), ('milk',), ('bread',)],\n",
      "     'Frequent items': [('apple',), ('milk',), ('bread',)],\n",
      "     'Support data': {('apple',): 0.6,\n",
      "                      ('bread',): 1.0,\n",
      "                      ('milk',): 1.0,\n",
      "                      ('nuts',): 0.4}},\n",
      " 2: {'Candidates': [('apple', 'nuts'),\n",
      "                    ('apple', 'milk'),\n",
      "                    ('apple', 'bread'),\n",
      "                    ('milk', 'nuts'),\n",
      "                    ('bread', 'nuts'),\n",
      "                    ('bread', 'milk')],\n",
      "     'Frequent items': [('apple', 'milk'),\n",
      "                        ('apple', 'bread'),\n",
      "                        ('bread', 'milk')],\n",
      "     'Support data': {('apple', 'bread'): 0.6,\n",
      "                      ('apple', 'milk'): 0.6,\n",
      "                      ('apple', 'nuts'): 0.2,\n",
      "                      ('bread', 'milk'): 1.0,\n",
      "                      ('bread', 'nuts'): 0.4,\n",
      "                      ('milk', 'nuts'): 0.4}},\n",
      " 3: {'Candidates': [('apple', 'milk', 'nuts'),\n",
      "                    ('apple', 'bread', 'nuts'),\n",
      "                    ('apple', 'bread', 'milk'),\n",
      "                    ('bread', 'milk', 'nuts')],\n",
      "     'Frequent items': [('apple', 'bread', 'milk')],\n",
      "     'Support data': {('apple', 'bread', 'milk'): 0.6,\n",
      "                      ('apple', 'bread', 'nuts'): 0.2,\n",
      "                      ('apple', 'milk', 'nuts'): 0.2,\n",
      "                      ('bread', 'milk', 'nuts'): 0.4}},\n",
      " 4: {'Candidates': [('apple', 'bread', 'milk', 'nuts')],\n",
      "     'Frequent items': [],\n",
      "     'Support data': {('apple', 'bread', 'milk', 'nuts'): 0.2}}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "support_map = {}\n",
    "\n",
    "for k in range(1, len(unique_items) + 1):\n",
    "    candidates_k = create_candidates_from_unique_items(unique_items, k)\n",
    "    frequent_items_k, support_k = calculate_support(dataset, candidates_k)\n",
    "    support_map[k] = {\n",
    "        \"Candidates\": candidates_k,\n",
    "        \"Frequent items\": frequent_items_k,\n",
    "        \"Support data\": support_k\n",
    "    }\n",
    "\n",
    "get_support = lambda items: support_map[len(items)][\"Support data\"][items] \n",
    "\n",
    "pprint(support_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd462b9e-b620-4769-bf17-2578faef18f0",
   "metadata": {},
   "source": [
    "## Apriori main algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65e28eed-6a9d-4c03-8c30-7ca4486c710b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Convert itemset to a sorted tuple for consistent dict keys.\n",
    "def normalize_key(itemset):\n",
    "    return tuple(sorted(itemset))\n",
    "\n",
    "def generate_rules(min_confidence = 0.6):\n",
    "    rules = []\n",
    "    \n",
    "    for item in support_map.keys():\n",
    "        frequent_items = support_map[item][\"Frequent items\"]\n",
    "\n",
    "        for items in frequent_items: \n",
    "            pairs = generate_antecedent_consequent(list(items))\n",
    "\n",
    "            # print(pairs)\n",
    "\n",
    "            normalized_item_key = normalize_key(items)\n",
    "            combined_support = get_support(normalized_item_key)\n",
    "        \n",
    "            for antecedent, consequent in pairs:\n",
    "                individual_support = get_support(normalize_key(antecedent))\n",
    "\n",
    "                # print(combined_support, individual_support)\n",
    "    \n",
    "                confidence = combined_support / individual_support\n",
    "                if confidence >= min_confidence:\n",
    "                    rules.append({\n",
    "                        \"Antecedent\": antecedent,\n",
    "                        \"Consequent\": consequent,\n",
    "                        \"Confidence\": round(confidence, 2)\n",
    "                    })\n",
    "    return sorted(rules, key = lambda record: record[\"Confidence\"], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b0af217-acaa-49c3-b606-8aa2a5ad0a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Antecedent': {'apple'}, 'Consequent': {'milk'}, 'Confidence': 1.0},\n",
       " {'Antecedent': {'apple'}, 'Consequent': {'bread'}, 'Confidence': 1.0},\n",
       " {'Antecedent': {'milk'}, 'Consequent': {'bread'}, 'Confidence': 1.0},\n",
       " {'Antecedent': {'bread'}, 'Consequent': {'milk'}, 'Confidence': 1.0},\n",
       " {'Antecedent': {'apple'}, 'Consequent': {'bread', 'milk'}, 'Confidence': 1.0},\n",
       " {'Antecedent': {'apple', 'milk'}, 'Consequent': {'bread'}, 'Confidence': 1.0},\n",
       " {'Antecedent': {'apple', 'bread'}, 'Consequent': {'milk'}, 'Confidence': 1.0},\n",
       " {'Antecedent': {'milk'}, 'Consequent': {'apple'}, 'Confidence': 0.6},\n",
       " {'Antecedent': {'bread'}, 'Consequent': {'apple'}, 'Confidence': 0.6},\n",
       " {'Antecedent': {'milk'}, 'Consequent': {'apple', 'bread'}, 'Confidence': 0.6},\n",
       " {'Antecedent': {'bread'}, 'Consequent': {'apple', 'milk'}, 'Confidence': 0.6},\n",
       " {'Antecedent': {'bread', 'milk'}, 'Consequent': {'apple'}, 'Confidence': 0.6}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules = generate_rules()\n",
    "rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2ae6e7-3381-40f3-8879-15b6da78b158",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python kernel developed by Saptarshi Dey",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
